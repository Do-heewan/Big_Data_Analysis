# 평가 지표

<br>

# 1. 이진 분류

이진 분류 시 사용되는 평가 지표

|지표|설명|범위|좋은 방향|
|----|----------------|----|-----|
|**Accuracy**|전체 중 맞춘 비율|0 ~ 1|높을수록 좋음|
|**Precision**|양성으로 예측한 것 중 실제 양성 비율|0 ~ 1|높을수록 좋음|
|**Recall**|실제 양성 중 맞춘 비율|0 ~ 1|높을수록 좋음|
|**F1 Score**|Precision과 Recall의 조화 평균|0 ~ 1|높을수록 좋음|
|**ROC-AUC**|다양한 threshold에서 모델의 구분 능력|0 ~ 1|높을수록 좋음|
|**Log Loss**|예측 확률 기반의 손실 함수|0 ~ $\inf$|낮을수록 좋음|

<br>

## 1.1 Accuracy

### 정의

전체 예측 중에서 모델이 정확하게 맞춘 비율

$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$

<br>

||||
|----|----------------|----|
|TP|True Positive|실제 값 양성 + 예측 값 양성|
|TN|True Negative|실제 값 양성 + 예측 값 음성|
|FP|False Positive|실제 값 음성 + 예측 값 양성|
|FN|False Negative|실제 값 음성 + 예측 값 음성|

<br>

### 단점

- **클래스 불균형에 민감함** : 95% 클래스가 0이라 하면, 모델은 0만 출력해도 정확도가 95%다.
- **오류의 중요도를 반영하지 못함** : FP와 FN이 중요할 때 부적합

<br>

## 1.2 Precision (정밀도)

### 정의

- 모델이 Positive라고 예측한 결과 중 실제로 Positive인 비율
- 모델이 긍정적이라고 판단한 경우, '이 판단이 실제로 얼마나 신뢰할 만한가?' 를 측정

$Precision = \frac{TP}{TP + FP}$

### Precision이 중요한 이유
- 오탐의 위험이 큰 상황
    - 스팸 필터링 : 정상 메일을 스팸으로 잘못 판단한다면 중요한 정보를 놓칠 수 있다.
    - 암 진단 : 암이 아닌데 암으로 진단한 경우
    - 제조 현장 : 시스템 이상이 없는데 이상으로 판정한 경우



### 한계점
FN의 경우를 고려하지 않음

<br>

## 1.3 Recall (재현율)

### 정의

실제 Positive인 클래스 중 모델이 정확하게 Positive로 분류한 비율

$Recall = \frac{TP}{TP + FN}$

### Recall이 중요한 이유
- 중요한 사건이나 질병, 위험 요소 등을 놓치지 않고 모두 찾아야 할 때 중요
    - 의료 진단 시스템
    - 금융 사기 탐지
    - 재난 예측 및 경고

### 한계점
- FP의 경우를 고려하지 않음

<br>

## 1.4 F-1 Score (조화평균)

### 정의

정밀도와 재현율을 하나로 통합하여 균형 잡힌 평가를 제공하는 지표

$F1 \ Score = 2 * \frac{Precision \ * \ Recall}{Precision \ + \ Recall}$

### 특징

- 둘 중 어느 하나만 높고 하나가 낮은 값을 가질 때 낮은 값을 보이며, 두 지표가 균형을 이루었을 때 높은 점수를 받게 됨
- 클래스 불균형이 심한 데이터셋에서 유용함

<br>

## 1.5 ROC Curve

### 정의
- 분류 모델의 성능을 시각적으로 평가하는 그래프
- True Positive Rate (TPR) 또는 Recall (민감도, Sensitivity)
- False Positive Rate (FPR) (1 - 특이도, 1 - Specificity)

$TPR = \frac{TP}{TP + FN}$

$FPR = \frac{FP}{FP + TN}$

### 장단점
- 다양한 Threshold에서 평가 가능
- 클래스 불균형에 강건한 평가 가능
- 정밀도를 반영하지 않음

### AUC (Area Under the Curve)
- ROC 곡선 아래의 면적으로 모델의 성능 지표
- 0 ~ 1 사이 값을 가짐

## 1.6 Log Loss (로그 손실)

### 정의
- 모델이 출력한 확률 값과 실제 값의 차이를 정량적으로 측정 (값이 작을 수록 좋음)
- Cross-Entropy Loss 라고 부름

$Log \ Loss = -\frac{1}{N}\sum[y_ilog(y_i) + (1-y_i)log(1-y_i)]$

### 장단점

- 확률적 예측이 중요한 문제에 유용 (로지스틱 회귀, 신경망 등)
- 작은 오류에도 민감하게 평가 가능
- 확률 출력이 필수적이여서 점수나 순위만 제공하는 모델에서는 사용이 어려움

<br>

# 2. 다중 클래스 분류

다중 클래스 분류 시 사용되는 평가 지표

|지표|설명|범위|좋은 방향|
|----|----------------|----|-----|
|**Accuracy**|전체 중 맞춘 비율|0 ~ 1|높을수록 좋음|
|**Macro F1**|클래스별 F1의 단순 평균(비율 무시)|0 ~ 1|높을수록 좋음|
|**Weighted F1**|클래스 비율을 반영한 F1 평균|0 ~ 1|높을수록 좋음|
|**Confusion Matrix**|클래스별 예측 정확도 / 오류 시각화|-|패턴 해석|
|**Top-k Accuracy**|정답이 상위 k개 예측 중에 포함되었는지|0 ~ 1|높을수록 좋음|

<br>

## 2.1 Macro F1 Score

### 정의
다중 클래스 분류 문제에서 사용되는 F1 Score
>전체 클래스의 성능을 균등하게 평가할 때 사용

$Macro \ F1 \ Score = \frac{1}{c}\sum F1 \ score_i$, C는 클래스 수

각 클래스 별 F1 Score를 먼저 계산하고 모든 클래스의 F1 Score를 동일한 가중치로 평균낸 값

### 특징 및 장단점
- 모든 클래스에 동일한 중요도를 부여하여 클래스 불균형이 큰 상황에서 소수의 클래스의 성능을 과소평가하지 않음
- 각 클래스별 성능을 동등하게 중요하게 고려해야 하는 문제에서 유리
- 빈도가 적은 클래스의 결과가 왜곡될 수 있음

<br>

## 2.2 Weighted F1 Score

### 정의
다중 클래스 분류 문제에서 클래스의 빈도가 불균형 할 때 사용되는 F1 Score
>데이터 개수가 많은 클래스는 성능 평가에서 비중이 커지고, 적은 클래스는 비중이 작아짐

$Weighted \ F1 \ Score = \frac{1}{\sum N_i} N_i * F1 \ Score_i$

각 클래스 별 출현 빈도를 반영하여 현실적인 평가 가능

### 특징 및 장단점
- 클래스 불균형이 있는 데이터에서 실제 성능을 정확하게 평가
- 데이터 빈도수가 매우 낮은 클래스의 성능이 점수에 거의 반영되지 않을 수 있으므로 Macro F1과 같은 지표를 추가로 고려해야 함

<br>

## 2.3 Confusion Matrix

### 정의
모델의 성능을 시각적으로 평가할 때 사용되는 표

### 장점
- 모델이 잘 맞춘 경우와 잘못 예측한 경우를 직관적이고 명확하게 시각화
- 클래스 간 혼동 패턴을 쉽게 파악
- 다른 성능 지표를 빠르게 계산 가능

<br>

## 2.4 Top-K Accuracy

### 정의
예측 결과가 상위 K개 클래스 중 포함되는지 평가

$Top \ K \ Accuracy = \frac{모델이 \ 예측한 \ 상위 \ K가 \ 결과 \ 중 \ 클래스를 \ 포함한 \ 횟수}{전체 \ 데이터 \ 수}$

### 예시

|데이터|실제 클래스|모델이 예측한 상위 3개 클래스|
|-----|----------|------------------------|
|1|고양이|강아지, **고양이**, 사자|
|2|사과|바나나, 오렌지, 수박|
|3|자동차|오토바이, **자동차**, 비행기|

>Top-3 Accuracy : 데이터1, 3에 대한 모델의 Top 3 예측은 정답을 포함하고 있음 => 2/3 = 66.6%

### 특징 및 장단점

- 모델이 어느 정도까지 실제 정답에 근접한 예측을 하고 있는지 평가할 때 사용
- 주로 추천 시스템, 자연어 처리 분야에서 사용
- K값이 너무 크면 평가의 의미가 줄어들 수 있음

<br>

# 3. 회귀 문제

회귀 문제에서 사용되는 평가 지표

|지표|설명|범위|좋은 방향|
|----|----------------|----|-----|
|**MSE**|평균 제곱 오차|0 ~ $\inf$|낮을수록 좋음|
|**RMSE**|평균 제곱근 오차|0 ~ $\inf$|낮을수록 좋음|
|**MAE**|평균 절대 오차|0 ~ $\inf$|낮을수록 좋음|
|**$R^2$ Score**|설명 가능한 분산 비율|-$\inf$ ~ 1|1에 가까울 수록 좋음|
|**MAPE**|평균 절대 백분율 오차|0 ~ $\inf$|낮을수록 좋음|

<br>

## 3.1 MSE (Mean Squared Error)

### 정의
예측한 값과 실제 값의 차이를 제곱하여 평균을 낸 값으로 오차의 크기를 정량적으로 평가

$MSE = \frac{1}{n}\sum (y_i-y_i)^2$

### 특징
큰 오차에 대해 민감한 특징이 있어 MSE를 손실 함수로 사용할 경우 큰 실수를 최소화 하도록 유도함

### 장단점
- 계산이 단순하고 직관적으로 이해가 쉬움
- 미분이 가능하며 최적화 과정에 유리함
- 큰 오차에 너무 민감하기에 이상치에 매우 취약함
- 오차 단위가 제곱이므로 실제 단위와 차이가 있다.

<br>

## 3.2 RMSE (Root Mean Squared Error)

### 정의
예측한 값과 실제 값의 차이를 제곱하여 평균을 낸 후, 제곱근을 씌운 값으로 오차의 크기를 정량적으로 평가

$RMSE = \sqrt{\frac{1}{n}\sum (y_i-y_i)^2}$

### 특징
실제 값과 동일한 단위로 표현되기 때문에 결과를 해석할 때 직관적임

### 장단점
- 계산이 간단하고 직관적으로 이해가 쉬움
- 여전히 큰 오차에 너무 민감하기 때문에 이상치에 취약함

<br>

## 3.3 MAE (Mean Absolute Error)

### 정의
예측한 값과 실제 값의 차이를 절대값으로 변환하여 평균을 계산한 값으로 '평균적으로 얼마나 틀렸는 가'를 단순히 보여줌

$MAE = \frac{1}{n}\sum |y_i - y_i|$

### 특징
실제 값과 동일한 단위로 표현되기 때문에 결과를 해석할 때 직관적임

### 장단점
- 계산이 간단하고 직관적으로 이해가 쉬움
- 이상치에 덜 민감하고 안정적임
- 미분 불가능한 지점이 존재할 수 있어 MSE보다 덜 효율적임
- 큰 오차에 집중해야 할 상황에선 MSE/RMSE 병행 사용 필요

<br>

## 3.4 MSE/RMSE/MAE 비교

|지표|계산 방식|단위 해석|이상치 민감도|해석 용이성|
|----|--------|-----------|----------|----------|
|MSE|오차 제곱의 평균|실제 단위의 제곱|매우 민감|중간|
|RMSE|MSE의 제곱근|실제 단위|민감|매우 좋음|
|MAE|오차 절대값의 평균|실제 단위|덜 민감|매우 좋음|

    매우 큰 오차를 줄이는데 집중할 경우 MSE 선택
    큰 오차에 집중하면서 안정적인 분석이 필요한 경우 RMSE 선택
    안정적인 분석이 필요할 경우 MAE 선택

<br>

## 3.5 $R^2$ (R-Squared, 결정 계수)

### 정의
모델이 주어진 데이터를 얼마나 잘 나타내는지 측정하는 지표

$R^2 = 1 -\frac{SS_{res}}{SS_{tot}}$

$SS_{res} = \sum(y_i - y_i)^2$, 잔차 제곱 합 (Residual Sum of Squares)

$SS_{tot} = \sum(y_i = y_i)^2$, 전체 분산 제곱합 (Total Sum of Squares)

### 장점
- 직관적이며 이해하기 쉬움
- 서로 다른 모델의 성능을 비교할 때 유용

### 단점
- 오직 선형관계만 반영하므로 비선형 모델에서는 해석이 제한적일 수 있음
- 데이터의 개수가 적을 때는 값이 높게 나오는 경우가 있어 과적합에 주의해야 함
- 변수가 많아질수록 결정계수 값이 증가함

### 예시

<br>

## 3.6 Adjusted $R^2$ (조정된 결정계수)

### 정의
변수가 많아질 수록 R^2값이 증가하는 문제를 해결하기 위해 조정된 결정계수

$Adjusted \ R^2 = 1 - (1-R^2)\frac{n-1}{n-k-1}$, n : 데이터의 개수, k : 독립변수의 개수

### 특징
변수의 개수가 많아질 수록 페널티를 부여하기 때문에 불필요한 변수를 추가할 경우 성능이 낮아지고 유의미한 변수가 추가될 경우 성능이 좋아지는 특징이 있음

변수가 많을 때 유용함

### 장점
- 변수 개수를 고려하여 모델의 실제 설명력을 더 정확히 반영
- 과적합을 방지하는데 효과적

### 단점
- 데이터의 개수가 적을 경우 정확도가 떨어짐

<br>

## 3.7 MAPE (Mean Percentage Error)

### 정의
실제 값과 예측 값의 차이를 절대값 백분율로 변환하여 평균을 나타낸 값

$MAPE = \frac{100}{n}\sum|\frac{y_i - y_i}{y_i}|$

백분율로 표현하기 때문에 매우 직관적인 지표로 사용 가능

### 특징
예측 오차를 백분율로 나타내기 때문에 직관적으로 이해하기 쉬움

### 장점
- 서로 다른 규모를 가진 데이터를 비교할 때 유리함

### 단점
- 실제 값이 0 또는 매우 작을 때 값이 급격히 커지는 문제가 있음
- 또한 실제 값이 음수일 경우 사용이 어려움
- 데이터가 0에 가까울 경우 MAE 혹은 RMSE를 추가로 고려해야 함

<br>

# 4. 평가지표 비교